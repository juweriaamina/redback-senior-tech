{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Patient ID  Age     Sex  Cholesterol Blood Pressure  Heart Rate  Diabetes  \\\n",
      "0    BMW7812   67    Male          208         158/88          72         0   \n",
      "1    CZE1114   21    Male          389         165/93          98         1   \n",
      "2    BNI9906   21  Female          324         174/99          72         1   \n",
      "3    JLN3497   84    Male          383         163100          73         1   \n",
      "4    GFO8847   66    Male          318          91/88          93         1   \n",
      "\n",
      "   Family History  Smoking  Obesity  ...  Sedentary Hours Per Day  Income  \\\n",
      "0               0        1        0  ...                 6.615001  261404   \n",
      "1               1        1        1  ...                 4.963459  285768   \n",
      "2               0        0        0  ...                 9.463426  235282   \n",
      "3               1        1        0  ...                 7.648981  125640   \n",
      "4               1        1        1  ...                 1.514821  160555   \n",
      "\n",
      "         BMI  Triglycerides  Physical Activity Days Per Week  \\\n",
      "0  31.251233            286                                0   \n",
      "1  27.194973            235                                1   \n",
      "2  28.176571            587                                4   \n",
      "3  36.464704            378                                3   \n",
      "4  21.809144            231                                1   \n",
      "\n",
      "   Sleep Hours Per Day    Country      Continent           Hemisphere  \\\n",
      "0                    6  Argentina  South America  Southern Hemisphere   \n",
      "1                    7     Canada  North America  Northern Hemisphere   \n",
      "2                    4     France         Europe  Northern Hemisphere   \n",
      "3                    4     Canada  North America  Northern Hemisphere   \n",
      "4                    5   Thailand           Asia  Northern Hemisphere   \n",
      "\n",
      "   Heart Attack Risk  \n",
      "0                  0  \n",
      "1                  0  \n",
      "2                  0  \n",
      "3                  0  \n",
      "4                  0  \n",
      "\n",
      "[5 rows x 26 columns]\n"
     ]
    }
   ],
   "source": [
    "# Step1:Load the dataset\n",
    "import pandas as pd\n",
    "file_path = \"HEART_ATTACK_PREDICTION_DATASET.csv\"\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Display the first few rows\n",
    "print(data.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import required library\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from imblearn.combine import SMOTEENN\n",
    "from tensorflow.keras.models import Sequential\n",
    "from sklearn.utils import shuffle\n",
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from keras_tuner.tuners import Hyperband\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 2: Data Cleaning\n",
    "data['Sex'] = data['Sex'].map({'Male': 1, 'Female': 0})\n",
    "data['Diet'] = data['Diet'].map({'Healthy': 3, 'Average': 2, 'Unhealthy': 1})\n",
    "\n",
    "# Splitting 'Blood Pressure' into 'Systolic' and 'Diastolic'\n",
    "data[['Systolic', 'Diastolic']] = data['Blood Pressure'].str.split('/', expand=True).astype(float)\n",
    "data.drop(['Blood Pressure', 'Patient ID', 'Country', 'Continent', 'Hemisphere'], axis=1, inplace=True)\n",
    "\n",
    "# Filling Missing Values\n",
    "data.fillna(data.median(), inplace=True)\n",
    "\n",
    "# Features and Target Variable\n",
    "X = data.drop('Heart Attack Risk', axis=1)\n",
    "y = data['Heart Attack Risk']\n",
    "\n",
    "# Handle Class Imbalance using SMOTEENN\n",
    "smote_enn = SMOTEENN(random_state=42)\n",
    "X_resampled, y_resampled = smote_enn.fit_resample(X, y)\n",
    "\n",
    "# Train-Test Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardizing Data\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#build the model and add early stopping\n",
    "\n",
    "def build_model(input_dim, learning_rate=0.001, reg_strength=0.01, dropout_rate=0.3):\n",
    "    model = Sequential([\n",
    "        Dense(128, activation='relu', input_dim=input_dim, kernel_regularizer=l2(reg_strength)),\n",
    "        Dropout(dropout_rate),\n",
    "        Dense(64, activation='relu', kernel_regularizer=l2(reg_strength)),\n",
    "        Dropout(dropout_rate),\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    \n",
    "    model.compile(optimizer=Adam(learning_rate=learning_rate),\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_2\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_2\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,944</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense_6 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │         \u001b[38;5;34m2,944\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_4 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_7 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m8,256\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_5 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_8 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m65\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">11,265</span> (44.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m11,265\u001b[0m (44.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">11,265</span> (44.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m11,265\u001b[0m (44.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 13ms/step - accuracy: 0.5667 - loss: 1.8064 - val_accuracy: 0.6566 - val_loss: 1.3998\n",
      "Epoch 2/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6616 - loss: 1.3338 - val_accuracy: 0.6623 - val_loss: 1.1034\n",
      "Epoch 3/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6295 - loss: 1.0854 - val_accuracy: 0.6679 - val_loss: 0.9349\n",
      "Epoch 4/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6445 - loss: 0.9151 - val_accuracy: 0.6811 - val_loss: 0.8168\n",
      "Epoch 5/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6746 - loss: 0.8093 - val_accuracy: 0.6774 - val_loss: 0.7469\n",
      "Epoch 6/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6621 - loss: 0.7456 - val_accuracy: 0.6792 - val_loss: 0.7065\n",
      "Epoch 7/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.6721 - loss: 0.7031 - val_accuracy: 0.6981 - val_loss: 0.6732\n",
      "Epoch 8/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.6815 - loss: 0.6822 - val_accuracy: 0.6660 - val_loss: 0.6546\n",
      "Epoch 9/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.6789 - loss: 0.6536 - val_accuracy: 0.6736 - val_loss: 0.6440\n",
      "Epoch 10/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6967 - loss: 0.6242 - val_accuracy: 0.6774 - val_loss: 0.6403\n",
      "Epoch 11/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6912 - loss: 0.6363 - val_accuracy: 0.6792 - val_loss: 0.6274\n",
      "Epoch 12/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7330 - loss: 0.6086 - val_accuracy: 0.6811 - val_loss: 0.6281\n",
      "Epoch 13/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6900 - loss: 0.6206 - val_accuracy: 0.6660 - val_loss: 0.6286\n",
      "Epoch 14/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7221 - loss: 0.6078 - val_accuracy: 0.6698 - val_loss: 0.6232\n",
      "Epoch 15/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7062 - loss: 0.6068 - val_accuracy: 0.6755 - val_loss: 0.6207\n",
      "Epoch 16/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6984 - loss: 0.6113 - val_accuracy: 0.6717 - val_loss: 0.6193\n",
      "Epoch 17/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7182 - loss: 0.5944 - val_accuracy: 0.6623 - val_loss: 0.6206\n",
      "Epoch 18/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7271 - loss: 0.5832 - val_accuracy: 0.6679 - val_loss: 0.6254\n",
      "Epoch 19/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7138 - loss: 0.6005 - val_accuracy: 0.6604 - val_loss: 0.6254\n",
      "Epoch 20/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7307 - loss: 0.5902 - val_accuracy: 0.6811 - val_loss: 0.6219\n",
      "Epoch 21/100\n",
      "\u001b[1m67/67\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7224 - loss: 0.5958 - val_accuracy: 0.6774 - val_loss: 0.6256\n",
      "Epoch 21: early stopping\n",
      "Restoring model weights from the end of the best epoch: 16.\n"
     ]
    }
   ],
   "source": [
    "model = build_model(input_dim=X_train_scaled.shape[1])\n",
    "model.summary()\n",
    "def get_callbacks():\n",
    "    return [\n",
    "        EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True, verbose=1)\n",
    "    ]\n",
    "\n",
    "\n",
    "callbacks = get_callbacks()\n",
    "history = model.fit(\n",
    "    X_train_scaled, y_train,\n",
    "    epochs=100,\n",
    "    validation_split=0.2,\n",
    "    callbacks=callbacks,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 66.16%\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.51      0.56       284\n",
      "           1       0.68      0.78      0.72       378\n",
      "\n",
      "    accuracy                           0.66       662\n",
      "   macro avg       0.65      0.64      0.64       662\n",
      "weighted avg       0.66      0.66      0.66       662\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Evaluate on Test Data\n",
    "test_loss, test_accuracy = model.evaluate(X_test_scaled, y_test, verbose=0)\n",
    "print(f\"Test Accuracy: {test_accuracy * 100:.2f}%\")\n",
    "\n",
    "# Predictions\n",
    "y_pred = (model.predict(X_test_scaled) > 0.5).astype(int)\n",
    "\n",
    "# Classification Report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Confusion Matrix\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.heatmap(confusion_matrix(y_test, y_pred), annot=True, fmt='d', cmap=\"Blues\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To improve the moodel accuracy lets add hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reloading Tuner from my_dir\\heart_attack_tuning\\tuner0.json\n",
      "\n",
      "Best Units: 256\n",
      "Best Dropout: 0.2\n",
      "Best Learning Rate: 0.001\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameter Tuning\n",
    "# from tensorflow.keras.layers import BatchNormalization, LeakyReLU\n",
    "\n",
    "# Define an Enhanced Model\n",
    "def create_improved_model():\n",
    "    model = Sequential([\n",
    "        Dense(256, kernel_regularizer=l2(0.01), input_dim=X_train_scaled.shape[1]),\n",
    "        BatchNormalization(),\n",
    "        LeakyReLU(alpha=0.1),\n",
    "        Dropout(0.3),\n",
    "        Dense(128, kernel_regularizer=l2(0.01)),\n",
    "        BatchNormalization(),\n",
    "        LeakyReLU(alpha=0.1),\n",
    "        Dropout(0.3),\n",
    "        Dense(64, kernel_regularizer=l2(0.01)),\n",
    "        BatchNormalization(),\n",
    "        LeakyReLU(alpha=0.1),\n",
    "        Dropout(0.2),\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    model.compile(optimizer=Adam(learning_rate=0.001),\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "\n",
    "# Hyperparameter Tuning\n",
    "tuner = Hyperband(\n",
    "    build_model,\n",
    "    objective='val_accuracy',\n",
    "    max_epochs=10,\n",
    "    factor=3,\n",
    "    directory='my_dir',\n",
    "    project_name='heart_attack_tuning'\n",
    ")\n",
    "\n",
    "tuner.search(X_train_scaled, y_train, validation_split=0.2, epochs=10, verbose=1)\n",
    "\n",
    "# Best Hyperparameters\n",
    "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
    "print(f\"\"\"\n",
    "Best Units: {best_hps.get('units')}\n",
    "Best Dropout: {best_hps.get('dropout')}\n",
    "Best Learning Rate: {best_hps.get('learning_rate')}\n",
    "\"\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training model 1/3 on fold 1\n",
      "Epoch 1/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 11ms/step - accuracy: 0.5818 - loss: 3.3072 - val_accuracy: 0.6591 - val_loss: 2.2786\n",
      "Epoch 2/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.6610 - loss: 2.0996 - val_accuracy: 0.6449 - val_loss: 1.6223\n",
      "Epoch 3/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.6681 - loss: 1.5135 - val_accuracy: 0.6383 - val_loss: 1.2655\n",
      "Epoch 4/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.6936 - loss: 1.1668 - val_accuracy: 0.6714 - val_loss: 1.0232\n",
      "Epoch 5/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7062 - loss: 0.9623 - val_accuracy: 0.6950 - val_loss: 0.8799\n",
      "Epoch 6/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.6974 - loss: 0.8565 - val_accuracy: 0.7016 - val_loss: 0.8117\n",
      "Epoch 7/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7037 - loss: 0.7815 - val_accuracy: 0.6686 - val_loss: 0.7822\n",
      "Epoch 8/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7219 - loss: 0.7251 - val_accuracy: 0.6827 - val_loss: 0.7302\n",
      "Epoch 9/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7176 - loss: 0.6830 - val_accuracy: 0.6846 - val_loss: 0.7272\n",
      "Epoch 10/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7103 - loss: 0.6804 - val_accuracy: 0.6695 - val_loss: 0.6940\n",
      "Epoch 11/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7348 - loss: 0.6498 - val_accuracy: 0.6780 - val_loss: 0.6854\n",
      "Epoch 12/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7189 - loss: 0.6505 - val_accuracy: 0.6874 - val_loss: 0.6649\n",
      "Epoch 13/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7255 - loss: 0.6216 - val_accuracy: 0.6903 - val_loss: 0.6518\n",
      "Epoch 14/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7275 - loss: 0.6180 - val_accuracy: 0.6931 - val_loss: 0.6697\n",
      "Epoch 15/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7276 - loss: 0.6320 - val_accuracy: 0.6704 - val_loss: 0.6755\n",
      "Epoch 16/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7164 - loss: 0.6224 - val_accuracy: 0.7035 - val_loss: 0.6591\n",
      "Epoch 17/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7193 - loss: 0.6181 - val_accuracy: 0.6912 - val_loss: 0.6592\n",
      "Epoch 18/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7209 - loss: 0.6194 - val_accuracy: 0.7035 - val_loss: 0.6326\n",
      "Epoch 19/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.7358 - loss: 0.6113 - val_accuracy: 0.7007 - val_loss: 0.6547\n",
      "Epoch 20/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7270 - loss: 0.6043 - val_accuracy: 0.6789 - val_loss: 0.6480\n",
      "Epoch 21/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7203 - loss: 0.6140 - val_accuracy: 0.6856 - val_loss: 0.6396\n",
      "Epoch 22/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7228 - loss: 0.6130 - val_accuracy: 0.6997 - val_loss: 0.6431\n",
      "Epoch 23/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7237 - loss: 0.6096 - val_accuracy: 0.6978 - val_loss: 0.6355\n",
      "Epoch 23: early stopping\n",
      "Restoring model weights from the end of the best epoch: 18.\n",
      "\n",
      "Training model 2/3 on fold 2\n",
      "Epoch 1/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 11ms/step - accuracy: 0.6150 - loss: 3.3009 - val_accuracy: 0.6497 - val_loss: 2.3182\n",
      "Epoch 2/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6638 - loss: 2.1082 - val_accuracy: 0.6487 - val_loss: 1.6229\n",
      "Epoch 3/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.6746 - loss: 1.5070 - val_accuracy: 0.6657 - val_loss: 1.2400\n",
      "Epoch 4/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.6909 - loss: 1.1669 - val_accuracy: 0.6789 - val_loss: 1.0139\n",
      "Epoch 5/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.7089 - loss: 0.9590 - val_accuracy: 0.6827 - val_loss: 0.8750\n",
      "Epoch 6/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7304 - loss: 0.8236 - val_accuracy: 0.6771 - val_loss: 0.8306\n",
      "Epoch 7/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7062 - loss: 0.7926 - val_accuracy: 0.6978 - val_loss: 0.7427\n",
      "Epoch 8/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7249 - loss: 0.7222 - val_accuracy: 0.6837 - val_loss: 0.7242\n",
      "Epoch 9/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7079 - loss: 0.7002 - val_accuracy: 0.6771 - val_loss: 0.7014\n",
      "Epoch 10/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7195 - loss: 0.6677 - val_accuracy: 0.6799 - val_loss: 0.6900\n",
      "Epoch 11/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7120 - loss: 0.6704 - val_accuracy: 0.6733 - val_loss: 0.6859\n",
      "Epoch 12/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7206 - loss: 0.6420 - val_accuracy: 0.6837 - val_loss: 0.6723\n",
      "Epoch 13/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7214 - loss: 0.6315 - val_accuracy: 0.7214 - val_loss: 0.6521\n",
      "Epoch 14/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7200 - loss: 0.6376 - val_accuracy: 0.6884 - val_loss: 0.6597\n",
      "Epoch 15/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7378 - loss: 0.6122 - val_accuracy: 0.6988 - val_loss: 0.6697\n",
      "Epoch 16/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7367 - loss: 0.6165 - val_accuracy: 0.6912 - val_loss: 0.6683\n",
      "Epoch 17/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7240 - loss: 0.6332 - val_accuracy: 0.6884 - val_loss: 0.6561\n",
      "Epoch 18/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7275 - loss: 0.6141 - val_accuracy: 0.7073 - val_loss: 0.6435\n",
      "Epoch 19/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7158 - loss: 0.6313 - val_accuracy: 0.6780 - val_loss: 0.6521\n",
      "Epoch 20/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7207 - loss: 0.6171 - val_accuracy: 0.7054 - val_loss: 0.6420\n",
      "Epoch 21/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7249 - loss: 0.6121 - val_accuracy: 0.6752 - val_loss: 0.6455\n",
      "Epoch 22/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7211 - loss: 0.6115 - val_accuracy: 0.6922 - val_loss: 0.6492\n",
      "Epoch 23/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7187 - loss: 0.6240 - val_accuracy: 0.7082 - val_loss: 0.6367\n",
      "Epoch 24/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7383 - loss: 0.5929 - val_accuracy: 0.6988 - val_loss: 0.6307\n",
      "Epoch 25/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7393 - loss: 0.6030 - val_accuracy: 0.7007 - val_loss: 0.6366\n",
      "Epoch 26/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7212 - loss: 0.6226 - val_accuracy: 0.6761 - val_loss: 0.6604\n",
      "Epoch 27/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7260 - loss: 0.6049 - val_accuracy: 0.6959 - val_loss: 0.6407\n",
      "Epoch 28/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7370 - loss: 0.6045 - val_accuracy: 0.6997 - val_loss: 0.6350\n",
      "Epoch 29/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7460 - loss: 0.5969 - val_accuracy: 0.6723 - val_loss: 0.6606\n",
      "Epoch 29: early stopping\n",
      "Restoring model weights from the end of the best epoch: 24.\n",
      "\n",
      "Training model 3/3 on fold 3\n",
      "Epoch 1/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 12ms/step - accuracy: 0.5913 - loss: 3.3068 - val_accuracy: 0.6298 - val_loss: 2.3045\n",
      "Epoch 2/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.6719 - loss: 2.0916 - val_accuracy: 0.6383 - val_loss: 1.6249\n",
      "Epoch 3/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.6837 - loss: 1.4906 - val_accuracy: 0.6884 - val_loss: 1.2235\n",
      "Epoch 4/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7046 - loss: 1.1417 - val_accuracy: 0.6686 - val_loss: 1.0138\n",
      "Epoch 5/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7100 - loss: 0.9566 - val_accuracy: 0.6818 - val_loss: 0.8846\n",
      "Epoch 6/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7067 - loss: 0.8406 - val_accuracy: 0.6714 - val_loss: 0.7948\n",
      "Epoch 7/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7197 - loss: 0.7567 - val_accuracy: 0.6893 - val_loss: 0.7470\n",
      "Epoch 8/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7085 - loss: 0.7234 - val_accuracy: 0.6837 - val_loss: 0.7249\n",
      "Epoch 9/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7368 - loss: 0.6756 - val_accuracy: 0.6893 - val_loss: 0.6945\n",
      "Epoch 10/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7239 - loss: 0.6572 - val_accuracy: 0.6941 - val_loss: 0.6993\n",
      "Epoch 11/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7325 - loss: 0.6390 - val_accuracy: 0.6941 - val_loss: 0.6745\n",
      "Epoch 12/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7322 - loss: 0.6336 - val_accuracy: 0.6941 - val_loss: 0.6644\n",
      "Epoch 13/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7346 - loss: 0.6366 - val_accuracy: 0.6922 - val_loss: 0.6593\n",
      "Epoch 14/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7143 - loss: 0.6408 - val_accuracy: 0.7044 - val_loss: 0.6523\n",
      "Epoch 15/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7208 - loss: 0.6177 - val_accuracy: 0.6912 - val_loss: 0.6495\n",
      "Epoch 16/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7451 - loss: 0.6065 - val_accuracy: 0.6978 - val_loss: 0.6572\n",
      "Epoch 17/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7183 - loss: 0.6208 - val_accuracy: 0.6846 - val_loss: 0.6514\n",
      "Epoch 18/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7175 - loss: 0.6279 - val_accuracy: 0.6959 - val_loss: 0.6688\n",
      "Epoch 19/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7208 - loss: 0.6112 - val_accuracy: 0.6941 - val_loss: 0.6491\n",
      "Epoch 20/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7199 - loss: 0.6082 - val_accuracy: 0.6572 - val_loss: 0.6772\n",
      "Epoch 21/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7261 - loss: 0.6177 - val_accuracy: 0.6827 - val_loss: 0.6537\n",
      "Epoch 22/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7200 - loss: 0.6004 - val_accuracy: 0.6874 - val_loss: 0.6346\n",
      "Epoch 23/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7260 - loss: 0.6110 - val_accuracy: 0.6884 - val_loss: 0.6428\n",
      "Epoch 24/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7154 - loss: 0.6118 - val_accuracy: 0.6874 - val_loss: 0.6339\n",
      "Epoch 25/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7367 - loss: 0.6055 - val_accuracy: 0.6941 - val_loss: 0.6379\n",
      "Epoch 26/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7200 - loss: 0.6217 - val_accuracy: 0.6903 - val_loss: 0.6360\n",
      "Epoch 27/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7139 - loss: 0.6161 - val_accuracy: 0.6997 - val_loss: 0.6329\n",
      "Epoch 28/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7308 - loss: 0.6029 - val_accuracy: 0.6742 - val_loss: 0.6448\n",
      "Epoch 29/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7196 - loss: 0.6010 - val_accuracy: 0.6780 - val_loss: 0.6510\n",
      "Epoch 30/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7349 - loss: 0.5960 - val_accuracy: 0.6950 - val_loss: 0.6559\n",
      "Epoch 31/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7201 - loss: 0.6263 - val_accuracy: 0.6978 - val_loss: 0.6410\n",
      "Epoch 32/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7228 - loss: 0.5990 - val_accuracy: 0.6969 - val_loss: 0.6471\n",
      "Epoch 32: early stopping\n",
      "Restoring model weights from the end of the best epoch: 27.\n",
      "\n",
      "Training model 1/3 on fold 4\n",
      "Epoch 1/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 13ms/step - accuracy: 0.5829 - loss: 3.3228 - val_accuracy: 0.6487 - val_loss: 2.3028\n",
      "Epoch 2/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.6581 - loss: 2.1197 - val_accuracy: 0.6582 - val_loss: 1.6168\n",
      "Epoch 3/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 10ms/step - accuracy: 0.6728 - loss: 1.5132 - val_accuracy: 0.6808 - val_loss: 1.2264\n",
      "Epoch 4/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.6972 - loss: 1.1659 - val_accuracy: 0.6950 - val_loss: 1.0018\n",
      "Epoch 5/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7005 - loss: 0.9847 - val_accuracy: 0.7233 - val_loss: 0.8633\n",
      "Epoch 6/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7068 - loss: 0.8616 - val_accuracy: 0.7148 - val_loss: 0.7935\n",
      "Epoch 7/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7120 - loss: 0.7857 - val_accuracy: 0.6978 - val_loss: 0.7448\n",
      "Epoch 8/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7175 - loss: 0.7293 - val_accuracy: 0.6978 - val_loss: 0.7146\n",
      "Epoch 9/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.7069 - loss: 0.7091 - val_accuracy: 0.6884 - val_loss: 0.7060\n",
      "Epoch 10/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.7100 - loss: 0.6952 - val_accuracy: 0.7195 - val_loss: 0.6610\n",
      "Epoch 11/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7122 - loss: 0.6672 - val_accuracy: 0.7299 - val_loss: 0.6570\n",
      "Epoch 12/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7180 - loss: 0.6612 - val_accuracy: 0.7186 - val_loss: 0.6555\n",
      "Epoch 13/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7199 - loss: 0.6436 - val_accuracy: 0.7224 - val_loss: 0.6296\n",
      "Epoch 14/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7309 - loss: 0.6338 - val_accuracy: 0.7290 - val_loss: 0.6253\n",
      "Epoch 15/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7183 - loss: 0.6422 - val_accuracy: 0.7073 - val_loss: 0.6375\n",
      "Epoch 16/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7191 - loss: 0.6422 - val_accuracy: 0.7309 - val_loss: 0.6418\n",
      "Epoch 17/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.7141 - loss: 0.6314 - val_accuracy: 0.7309 - val_loss: 0.6336\n",
      "Epoch 18/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.7344 - loss: 0.6280 - val_accuracy: 0.7035 - val_loss: 0.6242\n",
      "Epoch 19/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.7182 - loss: 0.6306 - val_accuracy: 0.7271 - val_loss: 0.6260\n",
      "Epoch 20/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.7278 - loss: 0.6270 - val_accuracy: 0.7290 - val_loss: 0.6140\n",
      "Epoch 21/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.7216 - loss: 0.6277 - val_accuracy: 0.7224 - val_loss: 0.6193\n",
      "Epoch 22/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.7294 - loss: 0.6186 - val_accuracy: 0.7205 - val_loss: 0.6213\n",
      "Epoch 23/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - accuracy: 0.7289 - loss: 0.6100 - val_accuracy: 0.7186 - val_loss: 0.6124\n",
      "Epoch 24/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7389 - loss: 0.6056 - val_accuracy: 0.7290 - val_loss: 0.6084\n",
      "Epoch 25/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.7309 - loss: 0.6137 - val_accuracy: 0.6997 - val_loss: 0.6157\n",
      "Epoch 26/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7321 - loss: 0.6057 - val_accuracy: 0.7280 - val_loss: 0.6270\n",
      "Epoch 27/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7197 - loss: 0.6304 - val_accuracy: 0.7167 - val_loss: 0.6211\n",
      "Epoch 28/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.7368 - loss: 0.6107 - val_accuracy: 0.7290 - val_loss: 0.6167\n",
      "Epoch 29/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7348 - loss: 0.6139 - val_accuracy: 0.7186 - val_loss: 0.6212\n",
      "Epoch 29: early stopping\n",
      "Restoring model weights from the end of the best epoch: 24.\n",
      "\n",
      "Training model 2/3 on fold 5\n",
      "Epoch 1/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 17ms/step - accuracy: 0.5631 - loss: 3.2932 - val_accuracy: 0.6837 - val_loss: 2.2297\n",
      "Epoch 2/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6652 - loss: 2.0267 - val_accuracy: 0.6704 - val_loss: 1.5251\n",
      "Epoch 3/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6814 - loss: 1.4310 - val_accuracy: 0.6884 - val_loss: 1.1637\n",
      "Epoch 4/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6886 - loss: 1.1080 - val_accuracy: 0.7195 - val_loss: 0.9372\n",
      "Epoch 5/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7098 - loss: 0.9155 - val_accuracy: 0.7186 - val_loss: 0.8307\n",
      "Epoch 6/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7035 - loss: 0.8217 - val_accuracy: 0.7195 - val_loss: 0.7614\n",
      "Epoch 7/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.6918 - loss: 0.7707 - val_accuracy: 0.7092 - val_loss: 0.7198\n",
      "Epoch 8/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.7165 - loss: 0.7216 - val_accuracy: 0.7186 - val_loss: 0.6766\n",
      "Epoch 9/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7180 - loss: 0.6796 - val_accuracy: 0.7092 - val_loss: 0.6614\n",
      "Epoch 10/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7205 - loss: 0.6621 - val_accuracy: 0.7101 - val_loss: 0.6591\n",
      "Epoch 11/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7249 - loss: 0.6497 - val_accuracy: 0.7110 - val_loss: 0.6508\n",
      "Epoch 12/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7215 - loss: 0.6476 - val_accuracy: 0.7092 - val_loss: 0.6446\n",
      "Epoch 13/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7014 - loss: 0.6574 - val_accuracy: 0.7318 - val_loss: 0.6251\n",
      "Epoch 14/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7182 - loss: 0.6250 - val_accuracy: 0.6969 - val_loss: 0.6518\n",
      "Epoch 15/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7209 - loss: 0.6277 - val_accuracy: 0.7120 - val_loss: 0.6393\n",
      "Epoch 16/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7238 - loss: 0.6213 - val_accuracy: 0.7148 - val_loss: 0.6211\n",
      "Epoch 17/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7124 - loss: 0.6314 - val_accuracy: 0.7073 - val_loss: 0.6335\n",
      "Epoch 18/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7110 - loss: 0.6344 - val_accuracy: 0.7422 - val_loss: 0.6112\n",
      "Epoch 19/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7256 - loss: 0.6162 - val_accuracy: 0.7101 - val_loss: 0.6290\n",
      "Epoch 20/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7205 - loss: 0.6291 - val_accuracy: 0.7195 - val_loss: 0.6345\n",
      "Epoch 21/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7321 - loss: 0.6156 - val_accuracy: 0.7290 - val_loss: 0.6129\n",
      "Epoch 22/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7114 - loss: 0.6338 - val_accuracy: 0.7148 - val_loss: 0.6136\n",
      "Epoch 23/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7179 - loss: 0.6246 - val_accuracy: 0.7299 - val_loss: 0.6134\n",
      "Epoch 23: early stopping\n",
      "Restoring model weights from the end of the best epoch: 18.\n",
      "\n",
      "Training model 3/3 on fold 6\n",
      "Epoch 1/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 12ms/step - accuracy: 0.5720 - loss: 3.2985 - val_accuracy: 0.6582 - val_loss: 2.2115\n",
      "Epoch 2/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.6613 - loss: 2.0232 - val_accuracy: 0.6704 - val_loss: 1.5248\n",
      "Epoch 3/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.6758 - loss: 1.4345 - val_accuracy: 0.6752 - val_loss: 1.1665\n",
      "Epoch 4/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.6849 - loss: 1.1146 - val_accuracy: 0.6856 - val_loss: 0.9525\n",
      "Epoch 5/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7028 - loss: 0.9242 - val_accuracy: 0.7148 - val_loss: 0.8366\n",
      "Epoch 6/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6990 - loss: 0.8173 - val_accuracy: 0.7177 - val_loss: 0.7576\n",
      "Epoch 7/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7245 - loss: 0.7496 - val_accuracy: 0.7177 - val_loss: 0.7241\n",
      "Epoch 8/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7210 - loss: 0.7070 - val_accuracy: 0.7148 - val_loss: 0.6984\n",
      "Epoch 9/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7005 - loss: 0.6774 - val_accuracy: 0.7035 - val_loss: 0.6673\n",
      "Epoch 10/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7087 - loss: 0.6667 - val_accuracy: 0.7337 - val_loss: 0.6409\n",
      "Epoch 11/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7171 - loss: 0.6472 - val_accuracy: 0.7016 - val_loss: 0.6472\n",
      "Epoch 12/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7097 - loss: 0.6518 - val_accuracy: 0.6959 - val_loss: 0.6412\n",
      "Epoch 13/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7196 - loss: 0.6258 - val_accuracy: 0.7158 - val_loss: 0.6320\n",
      "Epoch 14/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7180 - loss: 0.6365 - val_accuracy: 0.7214 - val_loss: 0.6225\n",
      "Epoch 15/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7225 - loss: 0.6175 - val_accuracy: 0.7195 - val_loss: 0.6177\n",
      "Epoch 16/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7255 - loss: 0.6183 - val_accuracy: 0.7110 - val_loss: 0.6294\n",
      "Epoch 17/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7233 - loss: 0.6209 - val_accuracy: 0.7167 - val_loss: 0.6424\n",
      "Epoch 18/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7232 - loss: 0.6154 - val_accuracy: 0.7120 - val_loss: 0.6439\n",
      "Epoch 19/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7177 - loss: 0.6351 - val_accuracy: 0.7110 - val_loss: 0.6262\n",
      "Epoch 20/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7284 - loss: 0.6207 - val_accuracy: 0.7252 - val_loss: 0.6022\n",
      "Epoch 21/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7365 - loss: 0.6045 - val_accuracy: 0.7177 - val_loss: 0.6228\n",
      "Epoch 22/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7253 - loss: 0.6178 - val_accuracy: 0.7195 - val_loss: 0.6155\n",
      "Epoch 23/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7021 - loss: 0.6276 - val_accuracy: 0.7195 - val_loss: 0.6170\n",
      "Epoch 24/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7242 - loss: 0.6117 - val_accuracy: 0.7167 - val_loss: 0.6131\n",
      "Epoch 25/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7194 - loss: 0.6180 - val_accuracy: 0.7167 - val_loss: 0.6139\n",
      "Epoch 25: early stopping\n",
      "Restoring model weights from the end of the best epoch: 20.\n",
      "\n",
      "Training model 1/3 on fold 7\n",
      "Epoch 1/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 17ms/step - accuracy: 0.5625 - loss: 3.3744 - val_accuracy: 0.6493 - val_loss: 2.3222\n",
      "Epoch 2/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6699 - loss: 2.1297 - val_accuracy: 0.6569 - val_loss: 1.6095\n",
      "Epoch 3/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7030 - loss: 1.4899 - val_accuracy: 0.6654 - val_loss: 1.2326\n",
      "Epoch 4/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.7001 - loss: 1.1611 - val_accuracy: 0.6919 - val_loss: 1.0053\n",
      "Epoch 5/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.6962 - loss: 0.9753 - val_accuracy: 0.6928 - val_loss: 0.8555\n",
      "Epoch 6/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7058 - loss: 0.8554 - val_accuracy: 0.6966 - val_loss: 0.7989\n",
      "Epoch 7/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7057 - loss: 0.7680 - val_accuracy: 0.6796 - val_loss: 0.7517\n",
      "Epoch 8/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7114 - loss: 0.7225 - val_accuracy: 0.6928 - val_loss: 0.7027\n",
      "Epoch 9/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7261 - loss: 0.6926 - val_accuracy: 0.6862 - val_loss: 0.6889\n",
      "Epoch 10/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7215 - loss: 0.6577 - val_accuracy: 0.6985 - val_loss: 0.6808\n",
      "Epoch 11/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7265 - loss: 0.6560 - val_accuracy: 0.6947 - val_loss: 0.6674\n",
      "Epoch 12/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7124 - loss: 0.6595 - val_accuracy: 0.6975 - val_loss: 0.6586\n",
      "Epoch 13/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7109 - loss: 0.6430 - val_accuracy: 0.6909 - val_loss: 0.6472\n",
      "Epoch 14/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7156 - loss: 0.6391 - val_accuracy: 0.7004 - val_loss: 0.6482\n",
      "Epoch 15/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7007 - loss: 0.6553 - val_accuracy: 0.6975 - val_loss: 0.6348\n",
      "Epoch 16/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7225 - loss: 0.6167 - val_accuracy: 0.6843 - val_loss: 0.6452\n",
      "Epoch 17/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7186 - loss: 0.6274 - val_accuracy: 0.6834 - val_loss: 0.6666\n",
      "Epoch 18/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7315 - loss: 0.6265 - val_accuracy: 0.7108 - val_loss: 0.6248\n",
      "Epoch 19/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7184 - loss: 0.6232 - val_accuracy: 0.6739 - val_loss: 0.6506\n",
      "Epoch 20/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7122 - loss: 0.6248 - val_accuracy: 0.7042 - val_loss: 0.6295\n",
      "Epoch 21/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7303 - loss: 0.6144 - val_accuracy: 0.7060 - val_loss: 0.6288\n",
      "Epoch 22/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7302 - loss: 0.6164 - val_accuracy: 0.7051 - val_loss: 0.6287\n",
      "Epoch 23/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7248 - loss: 0.6038 - val_accuracy: 0.6919 - val_loss: 0.6454\n",
      "Epoch 23: early stopping\n",
      "Restoring model weights from the end of the best epoch: 18.\n",
      "\n",
      "Training model 2/3 on fold 8\n",
      "Epoch 1/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 12ms/step - accuracy: 0.5922 - loss: 3.3170 - val_accuracy: 0.6616 - val_loss: 2.3223\n",
      "Epoch 2/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6607 - loss: 2.1387 - val_accuracy: 0.6446 - val_loss: 1.6309\n",
      "Epoch 3/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6810 - loss: 1.5150 - val_accuracy: 0.6767 - val_loss: 1.2379\n",
      "Epoch 4/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6819 - loss: 1.1797 - val_accuracy: 0.6947 - val_loss: 1.0107\n",
      "Epoch 5/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7051 - loss: 0.9785 - val_accuracy: 0.6881 - val_loss: 0.8883\n",
      "Epoch 6/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6919 - loss: 0.8694 - val_accuracy: 0.6975 - val_loss: 0.7938\n",
      "Epoch 7/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7081 - loss: 0.7811 - val_accuracy: 0.6862 - val_loss: 0.7582\n",
      "Epoch 8/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7218 - loss: 0.7119 - val_accuracy: 0.6928 - val_loss: 0.7169\n",
      "Epoch 9/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7094 - loss: 0.6969 - val_accuracy: 0.6805 - val_loss: 0.6932\n",
      "Epoch 10/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7173 - loss: 0.6770 - val_accuracy: 0.6975 - val_loss: 0.6872\n",
      "Epoch 11/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7105 - loss: 0.6537 - val_accuracy: 0.6758 - val_loss: 0.6750\n",
      "Epoch 12/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7105 - loss: 0.6535 - val_accuracy: 0.6928 - val_loss: 0.6501\n",
      "Epoch 13/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7115 - loss: 0.6491 - val_accuracy: 0.6957 - val_loss: 0.6569\n",
      "Epoch 14/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7214 - loss: 0.6409 - val_accuracy: 0.7004 - val_loss: 0.6512\n",
      "Epoch 15/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7147 - loss: 0.6374 - val_accuracy: 0.6994 - val_loss: 0.6719\n",
      "Epoch 16/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7202 - loss: 0.6380 - val_accuracy: 0.7013 - val_loss: 0.6435\n",
      "Epoch 17/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7192 - loss: 0.6321 - val_accuracy: 0.7174 - val_loss: 0.6272\n",
      "Epoch 18/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7261 - loss: 0.6320 - val_accuracy: 0.7259 - val_loss: 0.6323\n",
      "Epoch 19/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7267 - loss: 0.6297 - val_accuracy: 0.7079 - val_loss: 0.6316\n",
      "Epoch 20/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7235 - loss: 0.6151 - val_accuracy: 0.7032 - val_loss: 0.6294\n",
      "Epoch 21/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7207 - loss: 0.6238 - val_accuracy: 0.7136 - val_loss: 0.6194\n",
      "Epoch 22/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7198 - loss: 0.6178 - val_accuracy: 0.6928 - val_loss: 0.6344\n",
      "Epoch 23/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7368 - loss: 0.6029 - val_accuracy: 0.7108 - val_loss: 0.6359\n",
      "Epoch 24/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7317 - loss: 0.6093 - val_accuracy: 0.7174 - val_loss: 0.6271\n",
      "Epoch 25/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7142 - loss: 0.6350 - val_accuracy: 0.7278 - val_loss: 0.6308\n",
      "Epoch 26/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7359 - loss: 0.6185 - val_accuracy: 0.7042 - val_loss: 0.6302\n",
      "Epoch 26: early stopping\n",
      "Restoring model weights from the end of the best epoch: 21.\n",
      "\n",
      "Training model 3/3 on fold 9\n",
      "Epoch 1/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 15ms/step - accuracy: 0.6084 - loss: 3.2759 - val_accuracy: 0.6503 - val_loss: 2.2545\n",
      "Epoch 2/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.6548 - loss: 2.0630 - val_accuracy: 0.6560 - val_loss: 1.5592\n",
      "Epoch 3/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.6717 - loss: 1.4443 - val_accuracy: 0.6786 - val_loss: 1.1776\n",
      "Epoch 4/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.6840 - loss: 1.1188 - val_accuracy: 0.6966 - val_loss: 0.9559\n",
      "Epoch 5/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7031 - loss: 0.9235 - val_accuracy: 0.6938 - val_loss: 0.8399\n",
      "Epoch 6/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7214 - loss: 0.8079 - val_accuracy: 0.6928 - val_loss: 0.7655\n",
      "Epoch 7/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7099 - loss: 0.7508 - val_accuracy: 0.6853 - val_loss: 0.7245\n",
      "Epoch 8/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7033 - loss: 0.7183 - val_accuracy: 0.6947 - val_loss: 0.6949\n",
      "Epoch 9/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7156 - loss: 0.6853 - val_accuracy: 0.7070 - val_loss: 0.6775\n",
      "Epoch 10/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7196 - loss: 0.6765 - val_accuracy: 0.6994 - val_loss: 0.6625\n",
      "Epoch 11/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7137 - loss: 0.6645 - val_accuracy: 0.6881 - val_loss: 0.6448\n",
      "Epoch 12/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7244 - loss: 0.6335 - val_accuracy: 0.6985 - val_loss: 0.6628\n",
      "Epoch 13/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7149 - loss: 0.6391 - val_accuracy: 0.7174 - val_loss: 0.6398\n",
      "Epoch 14/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7340 - loss: 0.6254 - val_accuracy: 0.7060 - val_loss: 0.6275\n",
      "Epoch 15/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7332 - loss: 0.6092 - val_accuracy: 0.7042 - val_loss: 0.6363\n",
      "Epoch 16/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7171 - loss: 0.6243 - val_accuracy: 0.6985 - val_loss: 0.6372\n",
      "Epoch 17/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7231 - loss: 0.6224 - val_accuracy: 0.6947 - val_loss: 0.6403\n",
      "Epoch 18/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7361 - loss: 0.6156 - val_accuracy: 0.7098 - val_loss: 0.6235\n",
      "Epoch 19/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7252 - loss: 0.6255 - val_accuracy: 0.6985 - val_loss: 0.6421\n",
      "Epoch 20/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7141 - loss: 0.6321 - val_accuracy: 0.7042 - val_loss: 0.6382\n",
      "Epoch 21/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7381 - loss: 0.6131 - val_accuracy: 0.7098 - val_loss: 0.6254\n",
      "Epoch 22/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7117 - loss: 0.6169 - val_accuracy: 0.6881 - val_loss: 0.6481\n",
      "Epoch 23/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7283 - loss: 0.6121 - val_accuracy: 0.7202 - val_loss: 0.6227\n",
      "Epoch 24/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7260 - loss: 0.6174 - val_accuracy: 0.7108 - val_loss: 0.6195\n",
      "Epoch 25/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7323 - loss: 0.6153 - val_accuracy: 0.7070 - val_loss: 0.6280\n",
      "Epoch 26/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7272 - loss: 0.6174 - val_accuracy: 0.6966 - val_loss: 0.6340\n",
      "Epoch 27/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7123 - loss: 0.6208 - val_accuracy: 0.6928 - val_loss: 0.6374\n",
      "Epoch 28/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7374 - loss: 0.6063 - val_accuracy: 0.7164 - val_loss: 0.6153\n",
      "Epoch 29/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7248 - loss: 0.6125 - val_accuracy: 0.7401 - val_loss: 0.6178\n",
      "Epoch 30/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7183 - loss: 0.6271 - val_accuracy: 0.6947 - val_loss: 0.6260\n",
      "Epoch 31/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7222 - loss: 0.6282 - val_accuracy: 0.7023 - val_loss: 0.6275\n",
      "Epoch 32/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7361 - loss: 0.6059 - val_accuracy: 0.7079 - val_loss: 0.6264\n",
      "Epoch 33/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7281 - loss: 0.6087 - val_accuracy: 0.7174 - val_loss: 0.6165\n",
      "Epoch 33: early stopping\n",
      "Restoring model weights from the end of the best epoch: 28.\n",
      "\n",
      "Training model 1/3 on fold 10\n",
      "Epoch 1/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - accuracy: 0.5855 - loss: 3.3238 - val_accuracy: 0.6985 - val_loss: 2.2553\n",
      "Epoch 2/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6556 - loss: 2.0610 - val_accuracy: 0.6749 - val_loss: 1.5401\n",
      "Epoch 3/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6743 - loss: 1.4425 - val_accuracy: 0.6701 - val_loss: 1.1672\n",
      "Epoch 4/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6871 - loss: 1.1086 - val_accuracy: 0.6815 - val_loss: 0.9599\n",
      "Epoch 5/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6846 - loss: 0.9368 - val_accuracy: 0.7164 - val_loss: 0.8331\n",
      "Epoch 6/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7129 - loss: 0.8096 - val_accuracy: 0.7250 - val_loss: 0.7529\n",
      "Epoch 7/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7108 - loss: 0.7513 - val_accuracy: 0.7193 - val_loss: 0.7194\n",
      "Epoch 8/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7136 - loss: 0.7186 - val_accuracy: 0.7051 - val_loss: 0.6922\n",
      "Epoch 9/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7170 - loss: 0.6841 - val_accuracy: 0.7316 - val_loss: 0.6739\n",
      "Epoch 10/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7094 - loss: 0.6688 - val_accuracy: 0.7098 - val_loss: 0.6588\n",
      "Epoch 11/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7242 - loss: 0.6562 - val_accuracy: 0.7278 - val_loss: 0.6507\n",
      "Epoch 12/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7338 - loss: 0.6444 - val_accuracy: 0.7174 - val_loss: 0.6431\n",
      "Epoch 13/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7276 - loss: 0.6353 - val_accuracy: 0.7382 - val_loss: 0.6340\n",
      "Epoch 14/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7292 - loss: 0.6264 - val_accuracy: 0.7051 - val_loss: 0.6232\n",
      "Epoch 15/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7162 - loss: 0.6392 - val_accuracy: 0.7439 - val_loss: 0.6122\n",
      "Epoch 16/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7322 - loss: 0.6099 - val_accuracy: 0.7287 - val_loss: 0.6177\n",
      "Epoch 17/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7215 - loss: 0.6147 - val_accuracy: 0.7193 - val_loss: 0.6131\n",
      "Epoch 18/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7298 - loss: 0.6203 - val_accuracy: 0.7202 - val_loss: 0.6305\n",
      "Epoch 19/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6906 - loss: 0.6428 - val_accuracy: 0.7363 - val_loss: 0.6113\n",
      "Epoch 20/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7174 - loss: 0.6202 - val_accuracy: 0.7089 - val_loss: 0.6340\n",
      "Epoch 21/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7198 - loss: 0.6144 - val_accuracy: 0.7363 - val_loss: 0.6145\n",
      "Epoch 22/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7164 - loss: 0.6288 - val_accuracy: 0.7231 - val_loss: 0.6133\n",
      "Epoch 23/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7101 - loss: 0.6307 - val_accuracy: 0.7212 - val_loss: 0.6149\n",
      "Epoch 24/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7272 - loss: 0.6148 - val_accuracy: 0.7202 - val_loss: 0.6122\n",
      "Epoch 24: early stopping\n",
      "Restoring model weights from the end of the best epoch: 19.\n",
      "\n",
      "Training model 2/3 on fold 11\n",
      "Epoch 1/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 12ms/step - accuracy: 0.6013 - loss: 3.2574 - val_accuracy: 0.6767 - val_loss: 2.2400\n",
      "Epoch 2/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.6513 - loss: 2.0575 - val_accuracy: 0.6664 - val_loss: 1.5478\n",
      "Epoch 3/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.6673 - loss: 1.4599 - val_accuracy: 0.6645 - val_loss: 1.1902\n",
      "Epoch 4/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.6882 - loss: 1.1372 - val_accuracy: 0.7060 - val_loss: 0.9735\n",
      "Epoch 5/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7000 - loss: 0.9339 - val_accuracy: 0.7117 - val_loss: 0.8393\n",
      "Epoch 6/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6994 - loss: 0.8317 - val_accuracy: 0.7108 - val_loss: 0.7726\n",
      "Epoch 7/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7077 - loss: 0.7580 - val_accuracy: 0.7183 - val_loss: 0.7225\n",
      "Epoch 8/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7068 - loss: 0.7197 - val_accuracy: 0.7439 - val_loss: 0.6809\n",
      "Epoch 9/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7042 - loss: 0.7009 - val_accuracy: 0.7117 - val_loss: 0.6615\n",
      "Epoch 10/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.6962 - loss: 0.6762 - val_accuracy: 0.7004 - val_loss: 0.6599\n",
      "Epoch 11/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.7257 - loss: 0.6422 - val_accuracy: 0.6919 - val_loss: 0.6540\n",
      "Epoch 12/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7006 - loss: 0.6565 - val_accuracy: 0.7155 - val_loss: 0.6573\n",
      "Epoch 13/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7066 - loss: 0.6516 - val_accuracy: 0.7240 - val_loss: 0.6312\n",
      "Epoch 14/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7084 - loss: 0.6510 - val_accuracy: 0.7268 - val_loss: 0.6259\n",
      "Epoch 15/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7243 - loss: 0.6255 - val_accuracy: 0.7023 - val_loss: 0.6479\n",
      "Epoch 16/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7043 - loss: 0.6430 - val_accuracy: 0.7335 - val_loss: 0.6291\n",
      "Epoch 17/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7249 - loss: 0.6124 - val_accuracy: 0.7079 - val_loss: 0.6355\n",
      "Epoch 18/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7161 - loss: 0.6301 - val_accuracy: 0.7316 - val_loss: 0.6130\n",
      "Epoch 19/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7187 - loss: 0.6227 - val_accuracy: 0.7127 - val_loss: 0.6155\n",
      "Epoch 20/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7125 - loss: 0.6252 - val_accuracy: 0.7108 - val_loss: 0.6236\n",
      "Epoch 21/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7131 - loss: 0.6239 - val_accuracy: 0.7174 - val_loss: 0.6086\n",
      "Epoch 22/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.7179 - loss: 0.6095 - val_accuracy: 0.7259 - val_loss: 0.6122\n",
      "Epoch 23/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7091 - loss: 0.6105 - val_accuracy: 0.7183 - val_loss: 0.6103\n",
      "Epoch 24/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7128 - loss: 0.6187 - val_accuracy: 0.7023 - val_loss: 0.6135\n",
      "Epoch 25/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7159 - loss: 0.6115 - val_accuracy: 0.7117 - val_loss: 0.6141\n",
      "Epoch 26/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7215 - loss: 0.6020 - val_accuracy: 0.7325 - val_loss: 0.6082\n",
      "Epoch 27/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7203 - loss: 0.6141 - val_accuracy: 0.7183 - val_loss: 0.6179\n",
      "Epoch 28/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7337 - loss: 0.5994 - val_accuracy: 0.7032 - val_loss: 0.6237\n",
      "Epoch 29/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.6924 - loss: 0.6128 - val_accuracy: 0.7164 - val_loss: 0.6192\n",
      "Epoch 30/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7226 - loss: 0.6082 - val_accuracy: 0.7193 - val_loss: 0.6158\n",
      "Epoch 31/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7115 - loss: 0.6149 - val_accuracy: 0.7212 - val_loss: 0.6067\n",
      "Epoch 32/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7193 - loss: 0.6007 - val_accuracy: 0.7202 - val_loss: 0.5951\n",
      "Epoch 33/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7250 - loss: 0.5978 - val_accuracy: 0.7060 - val_loss: 0.6280\n",
      "Epoch 34/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.7245 - loss: 0.6040 - val_accuracy: 0.7127 - val_loss: 0.6138\n",
      "Epoch 35/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 11ms/step - accuracy: 0.7036 - loss: 0.6173 - val_accuracy: 0.7240 - val_loss: 0.6119\n",
      "Epoch 36/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7273 - loss: 0.5990 - val_accuracy: 0.6947 - val_loss: 0.6129\n",
      "Epoch 37/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 12ms/step - accuracy: 0.7146 - loss: 0.6119 - val_accuracy: 0.7420 - val_loss: 0.6037\n",
      "Epoch 37: early stopping\n",
      "Restoring model weights from the end of the best epoch: 32.\n",
      "\n",
      "Training model 3/3 on fold 12\n",
      "Epoch 1/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 13ms/step - accuracy: 0.5863 - loss: 3.2664 - val_accuracy: 0.6295 - val_loss: 2.2500\n",
      "Epoch 2/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.6701 - loss: 2.0547 - val_accuracy: 0.6380 - val_loss: 1.5681\n",
      "Epoch 3/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6822 - loss: 1.4609 - val_accuracy: 0.6815 - val_loss: 1.1786\n",
      "Epoch 4/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.6894 - loss: 1.1457 - val_accuracy: 0.7146 - val_loss: 0.9666\n",
      "Epoch 5/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6804 - loss: 0.9606 - val_accuracy: 0.6919 - val_loss: 0.8590\n",
      "Epoch 6/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7024 - loss: 0.8336 - val_accuracy: 0.7155 - val_loss: 0.7618\n",
      "Epoch 7/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6990 - loss: 0.7673 - val_accuracy: 0.7032 - val_loss: 0.7207\n",
      "Epoch 8/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6952 - loss: 0.7257 - val_accuracy: 0.7155 - val_loss: 0.6810\n",
      "Epoch 9/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7083 - loss: 0.6808 - val_accuracy: 0.7335 - val_loss: 0.6550\n",
      "Epoch 10/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7149 - loss: 0.6557 - val_accuracy: 0.7164 - val_loss: 0.6514\n",
      "Epoch 11/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7171 - loss: 0.6605 - val_accuracy: 0.7079 - val_loss: 0.6395\n",
      "Epoch 12/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7221 - loss: 0.6415 - val_accuracy: 0.7183 - val_loss: 0.6321\n",
      "Epoch 13/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7000 - loss: 0.6382 - val_accuracy: 0.7155 - val_loss: 0.6244\n",
      "Epoch 14/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7101 - loss: 0.6417 - val_accuracy: 0.7023 - val_loss: 0.6381\n",
      "Epoch 15/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7064 - loss: 0.6397 - val_accuracy: 0.7240 - val_loss: 0.6208\n",
      "Epoch 16/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7326 - loss: 0.6168 - val_accuracy: 0.7316 - val_loss: 0.6176\n",
      "Epoch 17/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7103 - loss: 0.6337 - val_accuracy: 0.7250 - val_loss: 0.6276\n",
      "Epoch 18/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7241 - loss: 0.6210 - val_accuracy: 0.7221 - val_loss: 0.6136\n",
      "Epoch 19/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7115 - loss: 0.6425 - val_accuracy: 0.7335 - val_loss: 0.6096\n",
      "Epoch 20/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7277 - loss: 0.6110 - val_accuracy: 0.7127 - val_loss: 0.6231\n",
      "Epoch 21/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7211 - loss: 0.6264 - val_accuracy: 0.7382 - val_loss: 0.6093\n",
      "Epoch 22/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7245 - loss: 0.6161 - val_accuracy: 0.7231 - val_loss: 0.6172\n",
      "Epoch 23/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7065 - loss: 0.6274 - val_accuracy: 0.7325 - val_loss: 0.6107\n",
      "Epoch 24/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7335 - loss: 0.6044 - val_accuracy: 0.7221 - val_loss: 0.6171\n",
      "Epoch 25/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7364 - loss: 0.6084 - val_accuracy: 0.7287 - val_loss: 0.6073\n",
      "Epoch 26/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7217 - loss: 0.6116 - val_accuracy: 0.7306 - val_loss: 0.6216\n",
      "Epoch 27/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6986 - loss: 0.6354 - val_accuracy: 0.7353 - val_loss: 0.6076\n",
      "Epoch 28/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7201 - loss: 0.6154 - val_accuracy: 0.7250 - val_loss: 0.6269\n",
      "Epoch 29/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7320 - loss: 0.6080 - val_accuracy: 0.7060 - val_loss: 0.6116\n",
      "Epoch 30/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7177 - loss: 0.6230 - val_accuracy: 0.7306 - val_loss: 0.6161\n",
      "Epoch 30: early stopping\n",
      "Restoring model weights from the end of the best epoch: 25.\n",
      "\n",
      "Training model 1/3 on fold 13\n",
      "Epoch 1/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - accuracy: 0.5769 - loss: 3.2645 - val_accuracy: 0.6758 - val_loss: 2.1404\n",
      "Epoch 2/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6692 - loss: 1.9601 - val_accuracy: 0.6616 - val_loss: 1.4500\n",
      "Epoch 3/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.6768 - loss: 1.3503 - val_accuracy: 0.6701 - val_loss: 1.0942\n",
      "Epoch 4/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7092 - loss: 1.0358 - val_accuracy: 0.7146 - val_loss: 0.8872\n",
      "Epoch 5/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.6923 - loss: 0.8795 - val_accuracy: 0.6966 - val_loss: 0.8039\n",
      "Epoch 6/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.6878 - loss: 0.7925 - val_accuracy: 0.7070 - val_loss: 0.7335\n",
      "Epoch 7/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.7056 - loss: 0.7227 - val_accuracy: 0.7089 - val_loss: 0.7043\n",
      "Epoch 8/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6956 - loss: 0.6977 - val_accuracy: 0.7335 - val_loss: 0.6619\n",
      "Epoch 9/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7111 - loss: 0.6693 - val_accuracy: 0.7023 - val_loss: 0.6561\n",
      "Epoch 10/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7152 - loss: 0.6605 - val_accuracy: 0.7117 - val_loss: 0.6519\n",
      "Epoch 11/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7212 - loss: 0.6527 - val_accuracy: 0.7287 - val_loss: 0.6307\n",
      "Epoch 12/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7153 - loss: 0.6250 - val_accuracy: 0.7401 - val_loss: 0.6233\n",
      "Epoch 13/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7147 - loss: 0.6340 - val_accuracy: 0.7127 - val_loss: 0.6341\n",
      "Epoch 14/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7166 - loss: 0.6326 - val_accuracy: 0.7117 - val_loss: 0.6284\n",
      "Epoch 15/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7123 - loss: 0.6361 - val_accuracy: 0.7032 - val_loss: 0.6303\n",
      "Epoch 16/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7076 - loss: 0.6431 - val_accuracy: 0.7079 - val_loss: 0.6230\n",
      "Epoch 17/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7205 - loss: 0.6215 - val_accuracy: 0.7155 - val_loss: 0.6149\n",
      "Epoch 18/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7173 - loss: 0.6232 - val_accuracy: 0.7306 - val_loss: 0.6170\n",
      "Epoch 19/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7309 - loss: 0.6097 - val_accuracy: 0.7335 - val_loss: 0.6068\n",
      "Epoch 20/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7125 - loss: 0.6146 - val_accuracy: 0.7316 - val_loss: 0.6045\n",
      "Epoch 21/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7301 - loss: 0.6158 - val_accuracy: 0.7023 - val_loss: 0.6088\n",
      "Epoch 22/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7150 - loss: 0.6104 - val_accuracy: 0.7136 - val_loss: 0.6185\n",
      "Epoch 23/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7115 - loss: 0.6257 - val_accuracy: 0.7117 - val_loss: 0.5957\n",
      "Epoch 24/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7044 - loss: 0.6214 - val_accuracy: 0.7231 - val_loss: 0.6121\n",
      "Epoch 25/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7190 - loss: 0.6156 - val_accuracy: 0.7155 - val_loss: 0.6096\n",
      "Epoch 26/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7259 - loss: 0.6129 - val_accuracy: 0.7202 - val_loss: 0.6089\n",
      "Epoch 27/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7132 - loss: 0.6201 - val_accuracy: 0.7268 - val_loss: 0.5931\n",
      "Epoch 28/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7102 - loss: 0.6222 - val_accuracy: 0.7439 - val_loss: 0.6015\n",
      "Epoch 29/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7264 - loss: 0.6152 - val_accuracy: 0.7401 - val_loss: 0.5970\n",
      "Epoch 30/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7249 - loss: 0.6156 - val_accuracy: 0.7250 - val_loss: 0.6024\n",
      "Epoch 31/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7339 - loss: 0.6079 - val_accuracy: 0.7467 - val_loss: 0.5981\n",
      "Epoch 32/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7285 - loss: 0.6115 - val_accuracy: 0.7259 - val_loss: 0.6044\n",
      "Epoch 32: early stopping\n",
      "Restoring model weights from the end of the best epoch: 27.\n",
      "\n",
      "Training model 2/3 on fold 14\n",
      "Epoch 1/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 14ms/step - accuracy: 0.5835 - loss: 3.2728 - val_accuracy: 0.6427 - val_loss: 2.2187\n",
      "Epoch 2/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.6636 - loss: 2.0160 - val_accuracy: 0.6493 - val_loss: 1.5369\n",
      "Epoch 3/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6869 - loss: 1.4206 - val_accuracy: 0.6701 - val_loss: 1.1636\n",
      "Epoch 4/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.6989 - loss: 1.1079 - val_accuracy: 0.6843 - val_loss: 0.9458\n",
      "Epoch 5/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.6954 - loss: 0.9389 - val_accuracy: 0.7146 - val_loss: 0.8151\n",
      "Epoch 6/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7096 - loss: 0.8213 - val_accuracy: 0.7023 - val_loss: 0.7572\n",
      "Epoch 7/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7200 - loss: 0.7471 - val_accuracy: 0.6928 - val_loss: 0.7293\n",
      "Epoch 8/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7152 - loss: 0.7098 - val_accuracy: 0.7193 - val_loss: 0.6749\n",
      "Epoch 9/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7170 - loss: 0.6804 - val_accuracy: 0.7202 - val_loss: 0.6588\n",
      "Epoch 10/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7155 - loss: 0.6573 - val_accuracy: 0.7183 - val_loss: 0.6483\n",
      "Epoch 11/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7155 - loss: 0.6481 - val_accuracy: 0.6909 - val_loss: 0.6415\n",
      "Epoch 12/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7228 - loss: 0.6405 - val_accuracy: 0.7193 - val_loss: 0.6370\n",
      "Epoch 13/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7157 - loss: 0.6346 - val_accuracy: 0.7212 - val_loss: 0.6271\n",
      "Epoch 14/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7121 - loss: 0.6383 - val_accuracy: 0.7146 - val_loss: 0.6358\n",
      "Epoch 15/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7272 - loss: 0.6277 - val_accuracy: 0.7051 - val_loss: 0.6342\n",
      "Epoch 16/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7043 - loss: 0.6376 - val_accuracy: 0.7250 - val_loss: 0.6092\n",
      "Epoch 17/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7272 - loss: 0.6220 - val_accuracy: 0.7070 - val_loss: 0.6152\n",
      "Epoch 18/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7207 - loss: 0.6240 - val_accuracy: 0.7202 - val_loss: 0.6113\n",
      "Epoch 19/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7312 - loss: 0.6132 - val_accuracy: 0.6957 - val_loss: 0.6124\n",
      "Epoch 20/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7105 - loss: 0.6266 - val_accuracy: 0.7221 - val_loss: 0.6165\n",
      "Epoch 21/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7196 - loss: 0.6190 - val_accuracy: 0.7278 - val_loss: 0.6182\n",
      "Epoch 21: early stopping\n",
      "Restoring model weights from the end of the best epoch: 16.\n",
      "\n",
      "Training model 3/3 on fold 15\n",
      "Epoch 1/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 10ms/step - accuracy: 0.6097 - loss: 3.2409 - val_accuracy: 0.6786 - val_loss: 2.1853\n",
      "Epoch 2/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 10ms/step - accuracy: 0.6601 - loss: 1.9959 - val_accuracy: 0.6711 - val_loss: 1.4962\n",
      "Epoch 3/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.6815 - loss: 1.3904 - val_accuracy: 0.6786 - val_loss: 1.1531\n",
      "Epoch 4/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.6975 - loss: 1.0933 - val_accuracy: 0.6777 - val_loss: 0.9545\n",
      "Epoch 5/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7031 - loss: 0.9181 - val_accuracy: 0.7070 - val_loss: 0.8291\n",
      "Epoch 6/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.7017 - loss: 0.8038 - val_accuracy: 0.7089 - val_loss: 0.7695\n",
      "Epoch 7/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7153 - loss: 0.7438 - val_accuracy: 0.7079 - val_loss: 0.7087\n",
      "Epoch 8/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7169 - loss: 0.6946 - val_accuracy: 0.7155 - val_loss: 0.6841\n",
      "Epoch 9/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7179 - loss: 0.6866 - val_accuracy: 0.7231 - val_loss: 0.6712\n",
      "Epoch 10/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7165 - loss: 0.6647 - val_accuracy: 0.7098 - val_loss: 0.6596\n",
      "Epoch 11/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7190 - loss: 0.6595 - val_accuracy: 0.7316 - val_loss: 0.6376\n",
      "Epoch 12/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7164 - loss: 0.6524 - val_accuracy: 0.7193 - val_loss: 0.6360\n",
      "Epoch 13/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7239 - loss: 0.6369 - val_accuracy: 0.7382 - val_loss: 0.6280\n",
      "Epoch 14/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7147 - loss: 0.6523 - val_accuracy: 0.7259 - val_loss: 0.6194\n",
      "Epoch 15/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7072 - loss: 0.6399 - val_accuracy: 0.7155 - val_loss: 0.6343\n",
      "Epoch 16/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7085 - loss: 0.6266 - val_accuracy: 0.7174 - val_loss: 0.6315\n",
      "Epoch 17/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7197 - loss: 0.6246 - val_accuracy: 0.7316 - val_loss: 0.6178\n",
      "Epoch 18/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7256 - loss: 0.6236 - val_accuracy: 0.7155 - val_loss: 0.6284\n",
      "Epoch 19/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7134 - loss: 0.6250 - val_accuracy: 0.7306 - val_loss: 0.6229\n",
      "Epoch 20/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7133 - loss: 0.6330 - val_accuracy: 0.7155 - val_loss: 0.6138\n",
      "Epoch 21/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7107 - loss: 0.6219 - val_accuracy: 0.7032 - val_loss: 0.6096\n",
      "Epoch 22/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7186 - loss: 0.6244 - val_accuracy: 0.7259 - val_loss: 0.6231\n",
      "Epoch 23/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7313 - loss: 0.6166 - val_accuracy: 0.7127 - val_loss: 0.6262\n",
      "Epoch 24/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7165 - loss: 0.6162 - val_accuracy: 0.7250 - val_loss: 0.6111\n",
      "Epoch 25/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7164 - loss: 0.6191 - val_accuracy: 0.7278 - val_loss: 0.6081\n",
      "Epoch 26/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7284 - loss: 0.6037 - val_accuracy: 0.7250 - val_loss: 0.6096\n",
      "Epoch 27/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7415 - loss: 0.5985 - val_accuracy: 0.7127 - val_loss: 0.6148\n",
      "Epoch 28/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7237 - loss: 0.6089 - val_accuracy: 0.7268 - val_loss: 0.6254\n",
      "Epoch 29/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7268 - loss: 0.6167 - val_accuracy: 0.7420 - val_loss: 0.5991\n",
      "Epoch 30/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7190 - loss: 0.6179 - val_accuracy: 0.7325 - val_loss: 0.6151\n",
      "Epoch 31/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7283 - loss: 0.6052 - val_accuracy: 0.7108 - val_loss: 0.6164\n",
      "Epoch 32/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7110 - loss: 0.6300 - val_accuracy: 0.7268 - val_loss: 0.6046\n",
      "Epoch 33/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.7385 - loss: 0.6055 - val_accuracy: 0.7098 - val_loss: 0.6318\n",
      "Epoch 34/50\n",
      "\u001b[1m133/133\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - accuracy: 0.7328 - loss: 0.6038 - val_accuracy: 0.7231 - val_loss: 0.6161\n",
      "Epoch 34: early stopping\n",
      "Restoring model weights from the end of the best epoch: 29.\n",
      "Cross-Validation Mean Accuracy: 72.12%\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
      "\u001b[1m21/21\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step\n",
      "\n",
      "Ensemble Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.63      0.64       284\n",
      "           1       0.73      0.75      0.74       378\n",
      "\n",
      "    accuracy                           0.69       662\n",
      "   macro avg       0.69      0.69      0.69       662\n",
      "weighted avg       0.69      0.69      0.69       662\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define the function to add Gaussian noise\n",
    "def add_gaussian_noise(data, mean=0, std=1):\n",
    "    noise = np.random.normal(mean, std, data.shape)\n",
    "    noisy_data = data + noise\n",
    "    return noisy_data           \n",
    "\n",
    "# Augment full training set with noisy data\n",
    "X_train_noisy = add_gaussian_noise(X_train_scaled, mean=0, std=0.01)  # Add noise with std=0.01\n",
    "X_train_aug = np.vstack((X_train_scaled, X_train_noisy))  # Combine original and noisy data\n",
    "y_train_aug = np.hstack((y_train, y_train))  # Duplicate the target labels for the augmented data\n",
    "X_train_aug, y_train_aug = shuffle(X_train_aug, y_train_aug, random_state=42)  # Shuffle to mix data\n",
    "\n",
    "# Cross-Validation Setup\n",
    "kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "cv_accuracies = []\n",
    "\n",
    "# Number of models for the ensemble\n",
    "n_models = 3\n",
    "models = []\n",
    "\n",
    "# Define EarlyStopping and LearningRateScheduler\n",
    "def get_callbacks():\n",
    "    return [\n",
    "        EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True, verbose=1)\n",
    "    ]\n",
    "\n",
    "# Perform cross-validation and train models\n",
    "for train_idx, val_idx in kf.split(X_train_aug, y_train_aug):\n",
    "    # Splitting the data for cross-validation fold\n",
    "    X_train_fold, X_val_fold = X_train_aug[train_idx], X_train_aug[val_idx]\n",
    "    y_train_fold, y_val_fold = y_train_aug[train_idx], y_train_aug[val_idx]\n",
    "\n",
    "    # Scale data\n",
    "    scaler = StandardScaler()\n",
    "    X_train_fold_scaled = scaler.fit_transform(X_train_fold)\n",
    "    X_val_fold_scaled = scaler.transform(X_val_fold)\n",
    "\n",
    "    # Train multiple models for each fold\n",
    "    for i in range(n_models):\n",
    "        print(f\"\\nTraining model {i+1}/{n_models} on fold {len(cv_accuracies)+1}\")\n",
    "        # Assuming create_improved_model() is defined elsewhere (e.g., returns a Keras model)\n",
    "        model = create_improved_model()\n",
    "\n",
    "        # Train the model\n",
    "        history = model.fit(\n",
    "            X_train_fold_scaled, y_train_fold,\n",
    "            validation_data=(X_val_fold_scaled, y_val_fold),\n",
    "            epochs=50,\n",
    "            batch_size=32,\n",
    "            callbacks=get_callbacks(),  # Add the callback here\n",
    "            verbose=1\n",
    "        )\n",
    "\n",
    "        # Evaluate fold accuracy\n",
    "        _, fold_acc = model.evaluate(X_val_fold_scaled, y_val_fold, verbose=0)\n",
    "        cv_accuracies.append(fold_acc)\n",
    "        models.append(model)\n",
    "\n",
    "# Output cross-validation results\n",
    "print(f\"Cross-Validation Mean Accuracy: {np.mean(cv_accuracies) * 100:.2f}%\")\n",
    "\n",
    "# Ensemble Predictions (using the trained models)\n",
    "ensemble_preds = np.mean([model.predict(X_test_scaled) for model in models], axis=0)\n",
    "\n",
    "# Convert to binary predictions (assuming it's a binary classification task)\n",
    "ensemble_preds = (ensemble_preds > 0.5).astype(int)\n",
    "\n",
    "# Final evaluation with classification report\n",
    "print(\"\\nEnsemble Classification Report:\")\n",
    "print(classification_report(y_test, ensemble_preds))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above code implements an improved and robust training strategy for a heart attack prediction model using ensemble learning, data augmentation, and cross-validation. It begins by augmenting the training data with Gaussian noise to simulate data variability, enhancing the model's generalization ability. The augmented dataset is then shuffled and passed through a 5-fold stratified cross-validation loop to ensure balanced evaluation across different subsets. For each fold, the training and validation sets are scaled using StandardScaler, and multiple models (3 in this case) are trained independently to form an ensemble. To prevent overfitting and optimize training, I added the EarlyStopping callback, which halts training if the validation loss does not improve for 5 consecutive epochs and restores the best model weights. This ensures more efficient training and better model performance. Finally, predictions from all trained models are averaged to create ensemble predictions, which are then evaluated using a classification report to assess performance across all classes. These enhancements collectively improve model reliability, reduce overfitting, and increase accuracy."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
